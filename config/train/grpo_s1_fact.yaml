model:
  pretrained_model_path:
    - "Qwen/Qwen2.5-3B-Instruct"
  dtype: "bfloat16"
  
  # FACT 配置
  use_fact: true
  fact_rank: 16
  fact_alpha: 32
  fact_dropout: 0.05
  fact_target_modules: ["q_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  fact_scale: 1.0

data:
  name: "gsm8k"

training:
  random_seed: 42
  epochs: 1
  learning_rate: 0.00001  # FACT 需要较高学习率
  max_gen_len: 256
  num_answers_per_question: 4
  temperature: 1.0
  max_grad_norm: 1.0
  ckpt_save_interval: 2000
  ckpt_dir: "checkpoints/grpo_fact_qwen3b"
  
  # GRPO-specific parameters
  use_ref_model: true
  epsilon_low: 0.2
  epsilon_high: 0.2
  beta: 0.01
  loss_type: "grpo" 