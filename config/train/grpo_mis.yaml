model:
  pretrained_model_path:
    - "ministral/Ministral-3b-instruct"
  dtype: "bfloat16"

data:
  name: "gsm8k"

training:
  random_seed: 42
  epochs: 1
  learning_rate: 0.00001
  max_gen_len: 256
  num_answers_per_question: 4 
  temperature: 1.0
  max_grad_norm: 1.0
  ckpt_save_interval: 3000
  ckpt_dir: "checkpoints/single_mis_grpo_custom"
  
  # GRPO-specific parameters
  use_ref_model: true          # Whether to use reference model for KL divergence
  epsilon_low: 0.2             # PPO clipping parameter (lower bound)
  epsilon_high: 0.2            # PPO clipping parameter (upper bound)  
  beta: 0.01                   # KL regularization coefficient
  loss_type: "grpo"            # Loss type: "grpo", "bnpo", or "dr_grpo"