checkpoint_dir: "meta-llama/Llama-3.2-3B-Instruct"
task: "gsm8k"
eval_samples: -1 # -1 for all
output_file: "evaluation_results_llama_gsm8k.json"
device: "cuda:0"
dtype: "bfloat16"
max_gen_len: 512
temperature: 1.0